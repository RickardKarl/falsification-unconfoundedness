{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from utils import names, name_order, name_shapes, name_colors, name_linestyles\n",
    "\n",
    "FOLDER_PATH = \"../results\"\n",
    "mpl.rcParams[\"axes.prop_cycle\"] = mpl.cycler(\n",
    "    color=[\n",
    "        \"#377eb8\",\n",
    "        \"#ff7f00\",\n",
    "        \"#4daf4a\",\n",
    "        \"#f781bf\",\n",
    "        \"#a65628\",\n",
    "        \"#984ea3\",\n",
    "        \"#999999\",\n",
    "        \"#e41a1c\",\n",
    "        \"#dede00\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "import warnings  # To suppress some warnings\n",
    "\n",
    "# Suppress the specific FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
    "\n",
    "# Get the five most recent files\n",
    "csv_files = glob.glob(os.path.join(FOLDER_PATH, \"*.csv\"))\n",
    "csv_files.sort(key=os.path.getmtime, reverse=True)\n",
    "recent_files = csv_files[:5]\n",
    "print(\"Five most recent CSV files:\")\n",
    "print(\"\\n\".join(recent_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "\n",
    "# Example names\n",
    "FILE_NAMES = [\n",
    "    \"experiment_B1-20250115_100145\",  \n",
    "    \"experiment_B2-20250115_100144\",\n",
    "    \"experiment_B2-20250116_153744\", \n",
    "    \"experiment_B3-20250115_100244\", \n",
    "    \"experiment_B4-20250115_100244\",\n",
    "    \"experiment_B4-20250116_153844\", \n",
    "]\n",
    "\n",
    "# Initialize list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Load DataFrames from the most recent files\n",
    "for file_name in FILE_NAMES:\n",
    "    file_path = os.path.join(FOLDER_PATH, f\"{file_name}.csv\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Rename methods using a dictionary lookup\n",
    "print(\"method found:\\n\", df[\"method\"].unique())\n",
    "df[\"method\"] = df[\"method\"].replace(names)\n",
    "print(\"renamed:\\n\", df[\"method\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and preprocess the dataframe for experiment B1\n",
    "table = df[df.experiment == \"experiment_B1\"]\n",
    "print(\"Methods:\", table[\"method\"].unique())\n",
    "table = table.drop(columns=[\"pval\", \"iterations\"])\n",
    "\n",
    "#table = table[table[\"method\"].isin(selected_methods_table)]\n",
    "\n",
    "# Group by and calculate mean and standard error\n",
    "table = (\n",
    "    table.groupby(\n",
    "        by=[\"conf_strength\", \"degree\", \"method\", \"transportability_violation\"]\n",
    "    )\n",
    "    .agg(\n",
    "        detection_mean=(\"detection\", \"mean\"),\n",
    "        detection_se=(\"detection\", lambda x: np.std(x, ddof=1) / np.sqrt(len(x))),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "table = table.rename(\n",
    "    columns={\n",
    "        \"conf_strength\": \"Unmeasured confounder\",\n",
    "        \"degree\": \"DGP\",\n",
    "        \"method\": \"Method\",\n",
    "        \"transportability_violation\": \"Transportability\",\n",
    "    }\n",
    ")\n",
    "table[\"Unmeasured confounder\"] = table[\"Unmeasured confounder\"].replace(\n",
    "    {0.0: \"No unmeasured confounder\", 1.0: \"Unmeasured confounder present\"}\n",
    ")\n",
    "table[\"Transportability\"] = table[\"Transportability\"].replace(\n",
    "    {1.0: \"Violated\", 0.0: \"Holds\"}\n",
    ")\n",
    "\n",
    "table[\"DGP\"] = table[\"DGP\"].replace({1: \"Linear\", 3: \"Cubic\"})\n",
    "\n",
    "# Pivot the table\n",
    "table_detection = table.pivot_table(\n",
    "    index=\"Method\",\n",
    "    columns=[\"Unmeasured confounder\", \"Transportability\", \"DGP\"],\n",
    "    values=[\"detection_mean\", \"detection_se\"],\n",
    ")\n",
    "\n",
    "# Format the table to include mean and SE in the format \"mean (.SE)\"\n",
    "formatted_table_detection = table_detection.apply(\n",
    "    lambda x: x[\"detection_mean\"].map(\"{:.2f}\".format)\n",
    "    + \" (\"\n",
    "    + x[\"detection_se\"].map(\"{:.2f}\".format).str.lstrip(\"0\")\n",
    "    + \")\",\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "\n",
    "# Sort based on method name\n",
    "formatted_table_detection.index = pd.Categorical(\n",
    "    formatted_table_detection.index, categories=name_order, ordered=True\n",
    ")\n",
    "formatted_table_detection = formatted_table_detection.sort_index()\n",
    "\n",
    "# Print the formatted table\n",
    "print(formatted_table_detection)\n",
    "\n",
    "# Save the formatted table as a LaTeX file\n",
    "formatted_table_detection.to_latex(\n",
    "    \"output/table_B1_detection.tex\",\n",
    "    multicolumn=True,\n",
    "    multicolumn_format=\"c\",\n",
    "    escape=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_df(dataframe, groupby_var):\n",
    "    # Drop unnecessary columns and compute the mean\n",
    "    dataframe = (\n",
    "        dataframe.drop(\n",
    "            columns=[\n",
    "                \"iterations\",\n",
    "                \"experiment\",\n",
    "                \"pval\",\n",
    "                \"degree\",\n",
    "                \"conf_strength\",\n",
    "            ]\n",
    "        )\n",
    "        .groupby(by=[\"method\", groupby_var])\n",
    "        .agg(detection_mean=(\"detection\", \"mean\"), count=(\"detection\", \"count\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "    dataframe[\"detection_se\"] = np.sqrt(\n",
    "        dataframe[\"detection_mean\"]\n",
    "        * (1 - dataframe[\"detection_mean\"])\n",
    "        / dataframe[\"count\"]\n",
    "    )\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for experiment B2 and get the unique methods\n",
    "\n",
    "\n",
    "selected_methods_plots_final = [\n",
    "    \"HGIC (Pearson)\",\n",
    "    #\"HGIC (Pearson-Tippett)\",\n",
    "    \"HGIC (KCIT-Tippett)\",\n",
    "    #\"Ours without bootstrap (Linear)\",\n",
    "    \"Ours (Linear)\",\n",
    "    \"Transp. test (Pearson)\",\n",
    "    #\"Transp. test (KCIT)\",\n",
    "]\n",
    "\n",
    "df_B2 = df[df.experiment == \"experiment_B2\"]\n",
    "df_B4 = df[df.experiment == \"experiment_B4\"]\n",
    "\n",
    "print(\"Methods:\", df_B2[\"method\"].unique())\n",
    "\n",
    "df_B2 = df_B2[df_B2[\"method\"].isin(selected_methods_plots_final)]\n",
    "df_B4 = df_B4[df_B4[\"method\"].isin(selected_methods_plots_final)]\n",
    "\n",
    "# Iterate over unique confounding strengths and sample sizes\n",
    "conf_strength = 1.0\n",
    "sns.set_context(\"talk\", font_scale=1.1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "for i, ns in enumerate([25, 100]):\n",
    "    tmp1 = df_B2[(df_B2.n_samples == ns) & (df_B2.conf_strength == conf_strength)]\n",
    "    tmp1 = pre_process_df(tmp1, \"n_envs\")\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=tmp1,\n",
    "        ax=ax[i],\n",
    "        x=\"n_envs\",\n",
    "        y=\"detection_mean\",\n",
    "        hue=\"method\",\n",
    "        style=\"method\",\n",
    "        markers=name_shapes,\n",
    "        palette=name_colors,\n",
    "        dashes=name_linestyles,\n",
    "        linewidth=3,\n",
    "        hue_order=[mname for mname in name_order if mname in df_B2.method.unique()],\n",
    "    )\n",
    "    for method, group in tmp1.groupby(\"method\"):\n",
    "        ax[i].errorbar(\n",
    "            group[\"n_envs\"],\n",
    "            group[\"detection_mean\"],\n",
    "            yerr=group[\"detection_se\"],\n",
    "            fmt=\"none\",  # 'none' so that the error bars don't come with a marker\n",
    "            capsize=5,  # Length of the error bar caps\n",
    "            color=name_colors[method],  # Set the color to match the line\n",
    "        )\n",
    "\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel(\"Falsification rate\")\n",
    "    else:\n",
    "        ax[i].set_ylabel(\"\")\n",
    "    ax[i].set_ylim(-0.02, 1.02)\n",
    "    ax[i].set_xlabel(\"Number of environments\")\n",
    "    ax[i].legend_.remove()\n",
    "    ax[i].set_title(f\"Fixed N = {ns}\")\n",
    "\n",
    "\n",
    "for i, ne in enumerate([10, 50]):\n",
    "    tmp2 = df_B4[(df_B4.n_envs == ne) & (df_B4.conf_strength == conf_strength)]\n",
    "    tmp2 = pre_process_df(tmp2, \"n_samples\")\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=tmp2,\n",
    "        ax=ax[i + 2],\n",
    "        x=\"n_samples\",\n",
    "        y=\"detection_mean\",\n",
    "        hue=\"method\",\n",
    "        style=\"method\",\n",
    "        markers=name_shapes,\n",
    "        palette=name_colors,\n",
    "        dashes=name_linestyles,\n",
    "        linewidth=3,\n",
    "        hue_order=[mname for mname in name_order if mname in df_B4.method.unique()],\n",
    "    )\n",
    "    for method, group in tmp2.groupby(\"method\"):\n",
    "        ax[i + 2].errorbar(\n",
    "            group[\"n_samples\"],\n",
    "            group[\"detection_mean\"],\n",
    "            yerr=group[\"detection_se\"],\n",
    "            fmt=\"none\",  # 'none' so that the error bars don't come with a marker\n",
    "            capsize=5,  # Length of the error bar caps\n",
    "            color=name_colors[method],  # Set the color to match the line\n",
    "        )\n",
    "\n",
    "    ax[i + 2].set_ylabel(\"\")\n",
    "    ax[i + 2].set_ylim(-0.02, 1.02)\n",
    "    ax[i + 2].set_xlabel(\"Number of samples\")\n",
    "    ax[i + 2].legend_.remove()\n",
    "    ax[i + 2].set_title(f\"Fixed K = {ne}\")\n",
    "\n",
    "\n",
    "if conf_strength == 0.0:\n",
    "    for j in range(4):  # Iterate over all subplots\n",
    "        ax[j].axhline(y=0.05, color=\"black\", linestyle=\"dotted\", linewidth=1.5)\n",
    "\n",
    "# Add a common legend below the plots\n",
    "handles, labels = ax[\n",
    "    0\n",
    "].get_legend_handles_labels()  # Get handles and labels from the first plot\n",
    "fig.legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    loc=\"center\",\n",
    "    bbox_to_anchor=(0.5, -0.075),\n",
    "    ncol=5,\n",
    "    fontsize=\"small\",\n",
    "    title_fontsize=\"small\",\n",
    ")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "output_path = (\n",
    "    f\"output/simulation_study_combined-{conf_strength}-vary_nsamples_nenvironments.pdf\"\n",
    ")\n",
    "plt.savefig(output_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for experiment B2 and get the unique methods\n",
    "\n",
    "df_B3 = df[df.experiment == \"experiment_B3\"]\n",
    "print(df_B3.method.unique())\n",
    "\n",
    "selected_methods_plots_final = [\n",
    "    \"HGIC (Pearson)\",\n",
    "    #\"HGIC (Pearson-Tippett)\",\n",
    "    \"HGIC (KCIT-Tippett)\",\n",
    "    \"Ours (Linear)\",\n",
    "    \"Transp. test (Pearson)\",\n",
    "    \"Transp. test (KCIT)\",\n",
    "]\n",
    "\n",
    "df_B3 = df_B3[df_B3[\"method\"].isin(selected_methods_plots_final)]\n",
    "\n",
    "# Iterate over unique confounding strengths and sample sizes\n",
    "sns.set_context(\n",
    "    \"talk\", font_scale=1.1\n",
    ")  # 'talk' is larger than default, scale up if needed\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "\n",
    "for i, c in enumerate([0.0, 1.0]):\n",
    "    tmp3 = df_B3[(df_B3.conf_strength == c)]\n",
    "    print(tmp3.columns)\n",
    "    tmp3 = pre_process_df(tmp3, \"n_observed_confounders\")\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=tmp3,\n",
    "        ax=ax[i],\n",
    "        x=\"n_observed_confounders\",\n",
    "        y=\"detection_mean\",\n",
    "        hue=\"method\",\n",
    "        style=\"method\",\n",
    "        markers=name_shapes,\n",
    "        palette=name_colors,\n",
    "        dashes=name_linestyles,\n",
    "        hue_order=[mname for mname in name_order if mname in df_B3.method.unique()],\n",
    "    )\n",
    "    for method, group in tmp3.groupby(\"method\"):\n",
    "        ax[i].errorbar(\n",
    "            group[\"n_observed_confounders\"],\n",
    "            group[\"detection_mean\"],\n",
    "            yerr=group[\"detection_se\"],\n",
    "            fmt=\"none\",  # 'none' so that the error bars don't come with a marker\n",
    "            capsize=5,  # Length of the error bar caps\n",
    "            color=name_colors[method],  # Set the color to match the line\n",
    "        )\n",
    "\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel(\"Falsification rate\")\n",
    "    else:\n",
    "        ax[i].set_ylabel(\"\")\n",
    "    ax[i].set_ylim(-0.02, 1.02)\n",
    "    ax[i].set_xlabel(\"Number of observed covariates\")\n",
    "    ax[i].legend_.remove()\n",
    "    ax[i].set_title(\n",
    "        \"No unmeasured confounder\" if c == 0.0 else \"Unmeasured confounder present\"\n",
    "    )\n",
    "    # ax[i].set_xticks([0,5,10,15])\n",
    "    if conf_strength == 0.0:\n",
    "        ax[i].axhline(y=0.05, color=\"black\", linestyle=\"dotted\", linewidth=1.5)\n",
    "\n",
    "\n",
    "# Add a common legend below the plots\n",
    "handles, labels = ax[\n",
    "    0\n",
    "].get_legend_handles_labels()  # Get handles and labels from the first plot\n",
    "fig.legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    loc=\"center\",\n",
    "    bbox_to_anchor=(0.5, -0.075),\n",
    "    ncol=3,\n",
    "    fontsize=\"small\",\n",
    "    title_fontsize=\"small\",\n",
    ")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "output_path = f\"figures/simulation_study_combined-vary_n_confounders.pdf\"\n",
    "plt.savefig(output_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for experiment B2 and get the unique methods\n",
    "\n",
    "\n",
    "selected_methods_plots_final = [\n",
    "    \"HGIC (Pearson)\",\n",
    "    \"HGIC (KCIT)\",\n",
    "    \"Ours (Linear)\",\n",
    "    \"Transp. test (Pearson)\",\n",
    "    # \"Transp. test (KCIT)\",\n",
    "]\n",
    "conf_strength = 1.0\n",
    "\n",
    "df_B2 = df[df.experiment == \"experiment_B2\"]\n",
    "df_B3 = df[df.experiment == \"experiment_B3\"]\n",
    "df_B4 = df[df.experiment == \"experiment_B4\"]\n",
    "\n",
    "print(\"Methods:\", df_B2[\"method\"].unique())\n",
    "\n",
    "df_B2 = df_B2[df_B2[\"method\"].isin(selected_methods_plots_final)]\n",
    "df_B3 = df_B3[df_B3[\"method\"].isin(selected_methods_plots_final)]\n",
    "df_B4 = df_B4[df_B4[\"method\"].isin(selected_methods_plots_final)]\n",
    "\n",
    "# assert df_B2['method'].unique() == df_B3['method'].unique() == df_B4['method'].unique()\n",
    "\n",
    "\n",
    "sns.set_context(\"talk\", font_scale=1.1)\n",
    "fig, ax = plt.subplots(1, 5, figsize=(25, 5))\n",
    "\n",
    "for i, ns in enumerate([25, 100]):\n",
    "    tmp1 = df_B2[(df_B2.n_samples == ns) & (df_B2.conf_strength == conf_strength)]\n",
    "    assert len(tmp1[\"n_observed_confounders\"].unique()) == 1\n",
    "    n_observed_confounders_B2 = tmp1[\"n_observed_confounders\"].unique()[0]\n",
    "    tmp1 = pre_process_df(tmp1, \"n_envs\")\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=tmp1,\n",
    "        ax=ax[i],\n",
    "        x=\"n_envs\",\n",
    "        y=\"detection_mean\",\n",
    "        hue=\"method\",\n",
    "        style=\"method\",\n",
    "        markers=name_shapes,\n",
    "        palette=name_colors,\n",
    "        dashes=name_linestyles,\n",
    "        linewidth=3,\n",
    "        hue_order=[mname for mname in name_order if mname in df_B2.method.unique()],\n",
    "    )\n",
    "    for method, group in tmp1.groupby(\"method\"):\n",
    "        ax[i].errorbar(\n",
    "            group[\"n_envs\"],\n",
    "            group[\"detection_mean\"],\n",
    "            yerr=group[\"detection_se\"],\n",
    "            fmt=\"none\",  # 'none' so that the error bars don't come with a marker\n",
    "            capsize=5,  # Length of the error bar caps\n",
    "            color=name_colors[method],  # Set the color to match the line\n",
    "        )\n",
    "\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel(\"Falsification rate\")\n",
    "    else:\n",
    "        ax[i].set_ylabel(\"\")\n",
    "    ax[i].set_ylim(-0.02, 1.02)\n",
    "    ax[i].set_xlabel(\"Number of environments $K$\")\n",
    "    ax[i].legend_.remove()\n",
    "    ax[i].set_title(f\"Fixed $(N,d) = ({ns},{n_observed_confounders_B2})$\")\n",
    "\n",
    "\n",
    "for i, ne in enumerate([10, 50]):\n",
    "    tmp2 = df_B4[(df_B4.n_envs == ne) & (df_B4.conf_strength == conf_strength)]\n",
    "    assert len(tmp2[\"n_observed_confounders\"].unique()) == 1\n",
    "    n_observed_confounders_B4 = tmp2[\"n_observed_confounders\"].unique()[0]\n",
    "    tmp2 = pre_process_df(tmp2, \"n_samples\")\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=tmp2,\n",
    "        ax=ax[i + 2],\n",
    "        x=\"n_samples\",\n",
    "        y=\"detection_mean\",\n",
    "        hue=\"method\",\n",
    "        style=\"method\",\n",
    "        markers=name_shapes,\n",
    "        palette=name_colors,\n",
    "        dashes=name_linestyles,\n",
    "        linewidth=3,\n",
    "        hue_order=[mname for mname in name_order if mname in df_B4.method.unique()],\n",
    "    )\n",
    "    for method, group in tmp2.groupby(\"method\"):\n",
    "        ax[i + 2].errorbar(\n",
    "            group[\"n_samples\"],\n",
    "            group[\"detection_mean\"],\n",
    "            yerr=group[\"detection_se\"],\n",
    "            fmt=\"none\",  # 'none' so that the error bars don't come with a marker\n",
    "            capsize=5,  # Length of the error bar caps\n",
    "            color=name_colors[method],  # Set the color to match the line\n",
    "        )\n",
    "\n",
    "    ax[i + 2].set_ylabel(\"\")\n",
    "    ax[i + 2].set_ylim(-0.02, 1.02)\n",
    "    ax[i + 2].set_xlabel(\"Number of samples $N$\")\n",
    "    ax[i + 2].legend_.remove()\n",
    "    ax[i + 2].set_title(f\"Fixed $(K,d) = ({ne},{n_observed_confounders_B4})$\")\n",
    "\n",
    "\n",
    "tmp3 = df_B3[(df_B3.conf_strength == conf_strength)]\n",
    "assert (len(tmp3[\"n_envs\"].unique()) == 1) and (len(tmp3[\"n_samples\"].unique()) == 1)\n",
    "n_environments_B3 = tmp3[\"n_envs\"].unique()[0]\n",
    "n_samples_B3 = tmp3[\"n_samples\"].unique()[0]\n",
    "tmp3 = pre_process_df(tmp3, \"n_observed_confounders\")\n",
    "\n",
    "sns.lineplot(\n",
    "    data=tmp3,\n",
    "    ax=ax[4],\n",
    "    x=\"n_observed_confounders\",\n",
    "    y=\"detection_mean\",\n",
    "    hue=\"method\",\n",
    "    style=\"method\",\n",
    "    markers=name_shapes,\n",
    "    palette=name_colors,\n",
    "    dashes=name_linestyles,\n",
    "    linewidth=3,\n",
    "    hue_order=[mname for mname in name_order if mname in df_B3.method.unique()],\n",
    ")\n",
    "for method, group in tmp3.groupby(\"method\"):\n",
    "    ax[4].errorbar(\n",
    "        group[\"n_observed_confounders\"],\n",
    "        group[\"detection_mean\"],\n",
    "        yerr=group[\"detection_se\"],\n",
    "        fmt=\"none\",  # 'none' so that the error bars don't come with a marker\n",
    "        capsize=5,  # Length of the error bar caps\n",
    "        color=name_colors[method],  # Set the color to match the line\n",
    "    )\n",
    "\n",
    "ax[4].set_ylabel(\"\")\n",
    "ax[4].set_ylim(-0.02, 1.02)\n",
    "ax[4].set_xlabel(\"Number of covariates $d$\")\n",
    "ax[4].legend_.remove()\n",
    "\n",
    "ax[4].set_title(f\"Fixed $(K,N) = ({n_environments_B3},{n_samples_B3})$\")\n",
    "\n",
    "if conf_strength == 0.0:\n",
    "    for j in range(4):  # Iterate over all subplots\n",
    "        ax[j].axhline(y=0.05, color=\"black\", linestyle=\"dotted\", linewidth=1.5)\n",
    "\n",
    "# Add a common legend below the plots\n",
    "handles, labels = ax[\n",
    "    0\n",
    "].get_legend_handles_labels()  # Get handles and labels from the first plot\n",
    "fig.legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    loc=\"center\",\n",
    "    bbox_to_anchor=(0.5, -0.075),\n",
    "    ncol=5,\n",
    "    fontsize=\"small\",\n",
    "    title_fontsize=\"small\",\n",
    ")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "output_path = (\n",
    "    f\"figures/simulation_study_combined-{conf_strength}.pdf\"\n",
    ")\n",
    "plt.savefig(output_path, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
